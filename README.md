## Задача
Напсать скрипт на php, который получит на вход указанный URL 
и сохранит локально папку c html кодом, локальной версией js и css, картинок: 
так, чтобы html файл можно было открыть локально в браузере 
и увидеть рабочую копию скачанной страницы из интернета.

Также нужно добавить параметр DEPTH в скрипт, 
который будет указывать глубину парсинга, 
так чтобы скачивались также страницы по указанным в коде ссылкам 
(с того же домена), с глубиной парсинга в DEPTH страниц.

В итоге должна скачиваться локальная версия сайта по указанному URL так, 
чтобы можно было кликать по ссылкам и переходить на другие локально 
скачанные страницы. Все файлы должны быть сохранены локально, 
чтобы страницы открывались и просматривались визуально как оригиналы, 
даже без доступа в интернет.

(*) при клике по ссылкам на страницы, которые не были скачаны, 
должен отображаться alert: “страница не скачана, открыть ее в интернете?” 
(с вариантами ответа Да/Нет), при выборе Да - открывать соотв. страницу в интернете; 
при выборе Нет - ничего не делать.

(*) в качестве примера см. программу [TeleportPro](https://www.softportal.com/software-53-teleport-pro.html) для Windows 
(нужно сделать примерно похожее решение в виде скриптов с GUI)

## Установка 
Выполните команды:
```
git clone git@github.com:nujensait/teleparser.git
composer update
```

## Запуск парсера
- Открыть в браузере:
http://teleparser/index.php

- Или с конкретными настройками:
http://teleparser/index.php?url=https://www.zabbix.com/documentation/5.0/ru/manual&depth=1&pattern=documentation/5.0/ru/manual

- Нажать на кнопку "Запуск"

## Запуск тестов
```
phpunit tests
```

## История разработки (TODO)
- [x] сохранение страниц для парсинга в БД
- [x] отображение ссылок на скачанные страницы
- [x] сохранение каждого парсинга в отдельный файл с меткой даты/времени
- [x] отображение ссылок на скачанные страницы
- [x] парсинг начиная от заданной страницы, с указанной глубиной и шаблоном ссылок
- [x] сохранять dokuwiki- версию файлов (помимо html)
- [ ] инструмент конвертации html в dokuwiki (на отдельной странице)
- [ ] ставить все загрузки в очередь на обработку, а скриптом только копить список ссылок для обработки в БД
- [ ] ссылки на нескачанные страницы заменять на внешние с alert-предложением перейти по ним
- [ ] локальное сохранение css, js, img (пока не работает)
- [ ] история или примеры ссылок (предлагать для заполнения)
- [ ] история парсинга (возможность скачать старые результаты)
- [ ] возможность скачать в архиве все файлы с сервера
- [ ] возможность удаления выбранных файлов парсинга (из БД и файлов физических)

## Контакты разработчика
Mikhail Ikonnikov <mishaikon@gmail.com>

